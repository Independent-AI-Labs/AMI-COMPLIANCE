# Prohibited AI Practice: Risk Assessments for Criminal Offences

## Description

This prohibition targets AI systems used for making risk assessments of natural persons in order to assess or predict the risk of a natural person committing a criminal offence, based solely on the profiling of a natural person or on assessing their personality traits and characteristics. This prohibition does not apply to AI systems used to support the human assessment of the involvement of a person in a criminal activity, which is already based on objective and verifiable facts directly linked to a criminal activity.

## Legal Basis

This practice is prohibited under **Article 5(1)(d) of the EU AI Act**.

## Key Elements

*   **Risk Assessment for Criminal Offences:** The AI system assesses or predicts the risk of a person committing a criminal offence.
*   **Solely Based on Profiling or Characteristics:** The assessment is based solely on profiling or personality traits.
*   **Exception for Human Assessment Support:** The prohibition does not apply when the AI system is used to support a human assessment that is based on objective and verifiable facts.

## Traces to Other Standards

*   **NIST AI RMF:** This practice raises significant concerns regarding fairness, accountability, and transparency, which are core principles of the NIST AI Risk Management Framework.
*   **ISO/IEC 42001:** The use of AI for predictive policing without human oversight and based on profiling would likely be considered a misuse of an AI system under ISO/IEC 42001.

