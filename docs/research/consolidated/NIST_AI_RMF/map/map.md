# NIST AI RMF: Map

## Description

The Map function establishes the context to frame risks related to an AI system. It is about recognizing the context and identifying risks related to that context. The information gathered while carrying out the Map function enables negative risk prevention and informs decisions for processes such as model management, as well as an initial decision about the appropriateness or the need for an AI solution.

## Key Elements

The Map function is broken down into the following categories and subcategories:

### MAP 1: Context is established and understood.

*   **MAP 1.1:** Intended purposes, potentially beneficial uses, context-specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented.
*   **MAP 1.2:** Interdisciplinary AI actors, competencies, skills, and capacities for establishing context reflect demographic diversity and broad domain and user experience expertise.
*   **MAP 1.3:** The organization's mission and relevant goals for AI technology are understood and documented.
*   **MAP 1.4:** The business value or context of business use has been clearly defined or – in the case of assessing existing AI systems – re-evaluated.
*   **MAP 1.5:** Organizational risk tolerances are determined and documented.
*   **MAP 1.6:** System requirements are elicited from and understood by relevant AI actors.

### MAP 2: Categorization of the AI system is performed.

*   **MAP 2.1:** The specific tasks and methods used to implement the tasks that the AI system will support are defined.
*   **MAP 2.2:** Information about the AI system's knowledge limits and how system output may be utilized and overseen by humans is documented.
*   **MAP 2.3:** Scientific integrity and TEVV considerations are identified and documented.

### MAP 3: AI capabilities, targeted usage, goals, and expected benefits and costs compared with appropriate benchmarks are understood.

*   **MAP 3.1:** Potential benefits of intended AI system functionality and performance are examined and documented.
*   **MAP 3.2:** Potential costs, including non-monetary costs, which result from expected or realized AI errors or system functionality and trustworthiness – as connected to organizational risk tolerance – are examined and documented.
*   **MAP 3.3:** Targeted application scope is specified and documented based on the system’s capability, established context, and AI system categorization.
*   **MAP 3.4:** Processes for operator and practitioner proficiency with AI system performance and trustworthiness – and relevant technical standards and certifications – are defined, assessed, and documented.
*   **MAP 3.5:** Processes for human oversight are defined, assessed, and documented in accordance with organizational policies from the GOVERN function.

### MAP 4: Risks and benefits are mapped for all components of the AI system including third-party software and data.

*   **MAP 4.1:** Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented.
*   **MAP 4.2:** Internal risk controls for components of the AI system, including third-party AI technologies, are identified and documented.

### MAP 5: Impacts to individuals, groups, communities, organizations, and society are characterized.

*   **MAP 5.1:** Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identified and documented.
*   **MAP 5.2:** Practices and personnel for supporting regular engagement with relevant AI actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.

## Traces to Other Standards

*   **EU AI Act:** The Map function aligns with the **risk identification and analysis** steps of the **Risk Management System (Article 9)** requirement in the EU AI Act. It also relates to the **Technical Documentation (Article 11 and Annex IV)** requirements, as much of the information gathered during the Map function would be part of the technical documentation. The categorization of the AI system in MAP 2 is also related to the **classification of high-risk AI systems (Article 6)**.

*   **ISO/IEC 42001 (AI Management System):** The Map function is aligned with **Clause 4: Context of the organization** and **Clause 6.1: Actions to address risks and opportunities** of ISO/IEC 42001. It provides the inputs for the risk assessment and treatment processes.

*   **ISO/IEC 27001 (Information Security Management System):** The Map function is aligned with **Clause 4: Context of the organization** and **Clause 6.1: Actions to address risks and opportunities** of ISO/IEC 27001, but with a focus on AI-specific risks.

*   **NIST RMF:** The Map function is aligned with the **Categorize** step of the NIST RMF, which involves categorizing the system and the information it processes.

