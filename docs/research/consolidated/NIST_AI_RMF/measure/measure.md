# NIST AI RMF: Measure

## Description

The Measure function employs quantitative, qualitative, or mixed-method tools, techniques, and methodologies to analyze, assess, benchmark, and monitor AI risk and related impacts. It uses knowledge relevant to AI risks identified in the Map function and informs the Manage function. AI systems should be tested before their deployment and regularly while in operation.

## Key Elements

The Measure function is broken down into the following categories and subcategories:

### MEASURE 1: Appropriate methods and metrics are identified and applied.

*   **MEASURE 1.1:** Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for implementation starting with the most significant AI risks.
*   **MEASURE 1.2:** Appropriateness of AI metrics and effectiveness of existing controls are regularly assessed and updated.
*   **MEASURE 1.3:** Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates.

### MEASURE 2: AI systems are evaluated for trustworthy characteristics.

*   **MEASURE 2.1:** Test sets, metrics, and details about the tools used during TEVV are documented.
*   **MEASURE 2.2:** Evaluations involving human subjects meet applicable requirements and are representative of the relevant population.
*   **MEASURE 2.3:** AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s).
*   **MEASURE 2.4:** The functionality and behavior of the AI system and its components are monitored when in production.
*   **MEASURE 2.5:** The AI system to be deployed is demonstrated to be valid and reliable.
*   **MEASURE 2.6:** The AI system is evaluated regularly for safety risks.
*   **MEASURE 2.7:** AI system security and resilience are evaluated and documented.
*   **MEASURE 2.8:** Risks associated with transparency and accountability are examined and documented.
*   **MEASURE 2.9:** The AI model is explained, validated, and documented, and AI system output is interpreted within its context.
*   **MEASURE 2.10:** Privacy risk of the AI system is examined and documented.
*   **MEASURE 2.11:** Fairness and bias are evaluated and results are documented.
*   **MEASURE 2.12:** Environmental impact and sustainability of AI model training and management activities are assessed and documented.
*   **MEASURE 2.13:** Effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented.

### MEASURE 3: Mechanisms for tracking identified AI risks over time are in place.

*   **MEASURE 3.1:** Approaches, personnel, and documentation are in place to regularly identify and track existing, unanticipated, and emergent AI risks.
*   **MEASURE 3.2:** Risk tracking approaches are considered for settings where AI risks are difficult to assess using currently available measurement techniques or where metrics are not yet available.

### MEASURE 4: Feedback about efficacy of measurement is gathered and assessed.

*   **MEASURE 4.1:** Measurement approaches for identifying AI risks are connected to deployment context(s) and informed through consultation with domain experts and other end users.
*   **MEASURE 4.2:** Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI actors.
*   **MEASURE 4.3:** Measurable performance improvements or declines based on consultations with relevant AI actors are identified and documented.

## Traces to Other Standards

*   **EU AI Act:** The Measure function is strongly aligned with the **Accuracy, robustness and cybersecurity (Article 15)** requirement of the EU AI Act, which requires providers to test and validate their systems against defined metrics. It also relates to the **testing procedures** mentioned in the **Risk Management System (Article 9)** and the **Technical Documentation (Article 11 and Annex IV)** requirements. The evaluation of trustworthy characteristics in MEASURE 2 is a key part of the conformity assessment process.

*   **ISO/IEC 42001 (AI Management System):** The Measure function is aligned with **Clause 9.1: Monitoring, measurement, analysis and evaluation** of ISO/IEC 42001. It provides the means to evaluate the performance of the AIMS.

*   **ISO/IEC 27001 (Information Security Management System):** The Measure function is aligned with **Clause 9.1: Monitoring, measurement, analysis and evaluation** of ISO/IEC 27001, but with a focus on AI-specific risks.

*   **NIST RMF:** The Measure function is aligned with the **Assess** step of the NIST RMF, which involves assessing the controls to determine if they are implemented correctly and producing the desired outcome.

