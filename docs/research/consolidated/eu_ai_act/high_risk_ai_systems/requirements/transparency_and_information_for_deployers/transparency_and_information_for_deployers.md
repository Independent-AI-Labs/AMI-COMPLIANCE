# High-Risk AI Systems Requirement: Transparency and Provision of Information to Deployers

## Description

High-risk AI systems must be designed and developed in such a way as to ensure that their operation is sufficiently transparent to enable deployers to interpret the system's output and use it appropriately. High-risk AI systems must also be accompanied by instructions for use that include concise, complete, correct, and clear information.

## Legal Basis

The requirement for transparency and provision of information to deployers is laid down in **Article 13 of the EU AI Act**.

## Key Elements

### Transparent Operation

High-risk AI systems must be designed and developed to be sufficiently transparent to allow deployers to:

*   **Interpret the system's output.**
*   **Use the system appropriately.**

### Instructions for Use

The instructions for use shall contain at least the following information:

*   **Identity and contact details of the provider.**
*   **Characteristics, capabilities and limitations of performance of the high-risk AI system**, including:
    *   Its intended purpose.
    *   The level of accuracy, robustness and cybersecurity.
    *   Known or foreseeable circumstances that may lead to risks to health, safety or fundamental rights.
    *   Where applicable, the technical capabilities and characteristics of the high-risk AI system to provide information that is relevant to explain its output.
    *   Its performance regarding specific persons or groups of persons on which the system is intended to be used.
    *   Specifications for the input data.
    *   Information to enable deployers to interpret the output of the high-risk AI system and use it appropriately.
*   **Changes to the high-risk AI system and its performance** which have been pre-determined by the provider.
*   **Human oversight measures**, including the technical measures put in place to facilitate the interpretation of the outputs of the high-risk AI systems by the deployers.
*   **The computational and hardware resources needed**, the expected lifetime of the high-risk AI system and any necessary maintenance and care measures.
*   A description of the mechanisms included within the high-risk AI system that allows deployers to properly collect, store and interpret the logs.

## Traces to Other Standards

*   **NIST AI RMF:** The transparency and information requirements are aligned with the **Govern** and **Map** functions of the NIST AI RMF.
    *   **Govern:** The `Govern` function includes establishing policies and procedures for transparency and communication.
    *   **Map:** The `Map` function includes documenting information about the AI system's capabilities and limitations.

*   **ISO/IEC 42001 (AI Management System):** These requirements are directly related to several controls in Annex A of ISO/IEC 42001:
    *   **A.8.2: System documentation and information for users**
    *   **A.9.4: Intended use of the AI system**

*   **ISO/IEC 27001 (Information Security Management System):** While not specific to AI, the principles of providing clear documentation and instructions for use are also relevant to information security. See **Clause 7.4: Communication** and **Clause 7.5: Documented information**.

*   **NIST RMF:** The provision of information to deployers is a key part of the **Prepare** and **Select** steps of the NIST RMF, as it enables system owners to make informed decisions about which systems to use and how to use them securely.

