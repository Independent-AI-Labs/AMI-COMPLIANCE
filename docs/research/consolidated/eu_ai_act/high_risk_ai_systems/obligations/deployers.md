# Obligations for Deployers of High-Risk AI Systems

## Description

Deployers are organisations or individuals that use high-risk AI systems in the course of their business. Article 26 outlines the obligations they must fulfil throughout operation, ranging from pre-deployment checks to user-facing disclosures.

## Legal Basis

Deployers’ responsibilities are covered in **Article 26 of the EU AI Act** (with cross-references to Articles 27-30 for impact assessments, cooperating users and specific sectors).

## Key Obligations

* **Operate within the intended purpose:** Deployers must use the system in accordance with the instructions for use and only within the operational limits defined by the provider (Article 26(1)).
* **Human oversight:** Assign competent personnel to perform the provider’s human-oversight measures and ensure they understand the system’s capabilities, limitations and automation bias (Article 26(2)).
* **Input data quality:** Ensure the data they supply into the system is relevant, sufficiently representative and error-free where they control input preparation (Article 26(1)).
* **Logs and monitoring:** Operate the logging mechanisms required by Article 12, store logs that fall under their control, and use them to monitor operation while respecting applicable data-protection rules (Article 26(3)).
* **Fundamental rights impact assessment:** Perform and document an assessment in line with Article 27 when deploying high-risk AI systems in areas listed in Annex III (Article 26(6)).
* **Post-market collaboration:** Cooperate with providers’ post-market monitoring by supplying relevant data and notifying them without undue delay about serious incidents or malfunctioning, as required by Articles 26(4) and 73.
* **Suspend and notify when risks emerge:** If use of the system could trigger an Article 79(1) risk, suspend operation without undue delay and inform the provider or distributor and the relevant market surveillance authority; escalate serious incidents immediately (Article 26(5)).
* **Transparency to affected persons:** When Article 52 or sectoral rules impose transparency obligations, ensure natural persons are informed that they are interacting with an AI system and provide the prescribed disclosures.
* **Inform the workforce:** Before workplace deployment, notify workers and their representatives that a high-risk AI system will be used, following national information procedures (Article 26(7)).
* **Registration checks for public bodies:** Public authorities and EU institutions must ensure the system is registered in the EU database prior to use and refuse deployment if registration is missing, alerting the provider or distributor (Article 26(8)).
* **Use provider disclosures for DPIAs:** Leverage the information supplied under Article 13 to complete any data-protection impact assessment required by GDPR Article 35 or Directive (EU) 2016/680 Article 27 (Article 26(9)).
* **Controls for post-remote biometric identification:** Obtain binding judicial or administrative authorisation before (or within 48 hours of) using post-remote biometric identification in criminal investigations, limit each use to what is strictly necessary, stop and delete data if authorisation is refused, document every deployment, and submit annual reports to market-surveillance and data-protection authorities while respecting operational secrecy (Article 26(10)-(11)).
* **Cooperate with competent authorities:** Support any action taken by regulators concerning the deployed system and provide requested information to implement the Regulation (Article 26(12)).
* **Special regimes:** Additional obligations apply for biometric identification (Article 29), law enforcement (Article 30) and workplace deployments, which must be mapped alongside national implementing rules.

## Traces to Other Standards

* **ISO/IEC 42001:** Clause 8 (Operation) and Annex A controls on human oversight, data governance and impact assessment align with deployer duties for training, change control and documenting risk treatment.
* **ISO/IEC 27001:** Clauses 7-10 provide the ISMS foundation for log retention, operator competence, and corrective action tracking.
* **NIST AI RMF / NIST RMF:** Deployers contribute to the Map, Measure and Manage functions (context setting, monitoring, incident response) and perform continuous monitoring (RMF M-1 to M-5).
