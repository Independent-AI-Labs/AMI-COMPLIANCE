# NIST AI RMF: Govern

## Description

The Govern function is a cross-cutting function that is infused throughout AI risk management and enables the other functions of the process. It cultivates and implements a culture of risk management within organizations designing, developing, deploying, evaluating, or acquiring AI systems.

## Key Elements

The Govern function is broken down into the following categories and subcategories:

### GOVERN 1: Policies, processes, procedures, and practices for AI risk management are in place, transparent, and implemented effectively.

*   **GOVERN 1.1:** Legal and regulatory requirements involving AI are understood, managed, and documented.
*   **GOVERN 1.2:** The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices.
*   **GOVERN 1.3:** Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization's risk tolerance.
*   **GOVERN 1.4:** The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.
*   **GOVERN 1.5:** Ongoing monitoring and periodic review of the risk management process and its outcomes are planned and organizational roles and responsibilities clearly defined.
*   **GOVERN 1.6:** Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.
*   **GOVERN 1.7:** Processes and procedures are in place for decommissioning and phasing out AI systems safely.

### GOVERN 2: Accountability structures are in place so that the appropriate teams and individuals are empowered, responsible, and trained for managing AI risks.

*   **GOVERN 2.1:** Roles and responsibilities and lines of communication related to managing AI risks are documented and are clear to individuals and teams throughout the organization.
*   **GOVERN 2.2:** The organization's personnel and partners receive AI risk management training.
*   **GOVERN 2.3:** Executive leadership of the organization takes responsibility for decisions about risks associated with AI system development and deployment.

### GOVERN 3: Workforce diversity, equity, inclusion, and accessibility processes are prioritized.

*   **GOVERN 3.1:** Decision-making related to managing AI risks throughout the lifecycle is informed by a diverse team.
*   **GOVERN 3.2:** Policies and procedures are in place to define and differentiate roles and responsibilities for human-AI configurations and oversight of AI systems.

### GOVERN 4: Organizational teams are committed to a culture that considers and communicates AI risk.

*   **GOVERN 4.1:** Organizational policies and practices are in place to foster a critical thinking and safety-first mindset.
*   **GOVERN 4.2:** Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly.
*   **GOVERN 4.3:** Organizational practices are in place to enable AI testing, identification of incidents, and information sharing.

### GOVERN 5: Processes are in place for robust engagement with relevant AI actors.

*   **GOVERN 5.1:** Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team.
*   **GOVERN 5.2:** Mechanisms are established to enable the team that developed or deployed AI systems to regularly incorporate adjudicated feedback from relevant AI actors into system design and implementation.

### GOVERN 6: Policies and procedures are in place to address AI risks and benefits arising from third-party software and data and other supply chain issues.

*   **GOVERN 6.1:** Policies and procedures are in place that address AI risks associated with third-party entities.
*   **GOVERN 6.2:** Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.

## Traces to Other Standards

*   **EU AI Act:** The Govern function in the NIST AI RMF is highly aligned with the requirements for a **Risk Management System (Article 9)** and the obligations of providers for **Quality Management System (Article 17)** in the EU AI Act. Both frameworks emphasize the importance of a systematic, documented, and continuous process for managing risks. The accountability structures in GOVERN 2 are also reflected in the EU AI Act's allocation of responsibilities to providers, deployers, and other actors.

*   **ISO/IEC 42001 (AI Management System):** The Govern function is the direct counterpart to the **Leadership (Clause 5)** and **Planning (Clause 6)** clauses of ISO/IEC 42001. It provides the framework for establishing and maintaining the AIMS.

*   **ISO/IEC 27001 (Information Security Management System):** The Govern function is also aligned with the **Leadership (Clause 5)** and **Planning (Clause 6)** clauses of ISO/IEC 27001, but with a focus on AI-specific risks. An organization's ISMS should be integrated with its AIMS, and the Govern function provides the bridge between the two.

*   **NIST RMF:** The Govern function is the foundation for the entire NIST RMF. It corresponds to the **Prepare** step at the organization level, which involves establishing the context and priorities for risk management.

