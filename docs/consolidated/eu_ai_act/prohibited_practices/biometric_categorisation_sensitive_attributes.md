# Prohibited AI Practice: Biometric Categorisation Based on Sensitive Attributes

## Description

This prohibition targets biometric categorisation systems that categorise individually natural persons based on their biometric data to deduce or infer their race, political opinions, trade union membership, religious or philosophical beliefs, sex life or sexual orientation. This prohibition does not cover any labelling or filtering of lawfully acquired biometric datasets, such as images, based on biometric data or categorizing of biometric data in the area of law enforcement.

## Legal Basis

This practice is prohibited under **Article 5(1)(g) of the EU AI Act**.

## Key Elements

*   **Biometric Categorisation:** The AI system categorises natural persons based on their biometric data.
*   **Sensitive Attributes:** The categorisation is used to deduce or infer sensitive attributes such as race, political opinions, or sexual orientation.
*   **Exception for Law Enforcement:** The prohibition does not cover labelling or filtering of lawfully acquired biometric datasets in the area of law enforcement.

## Traces to Other Standards

*   **NIST AI RMF:** This practice is a clear example of a system that could lead to discriminatory outcomes, which is a key risk area identified in the NIST AI Risk Management Framework.
*   **ISO/IEC 27701:** This practice would likely violate the privacy information management requirements of ISO/IEC 27701, as it involves the processing of sensitive personal data.

